<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Argusee: A Multi-Agent Collaborative Architecture for Automated Vulnerability Discovery | DARKNAVY</title>
<meta name=keywords content><meta name=description content="As we envisioned in DARKNAVY INSIGHT | The Most Imaginative New Applications of 2024:

The next generation of AI agents will have excellent reasoning and generalization abilities and be skilled at using a variety of security research tools, inheriting a wealth of human expert knowledge. They will be able to discover more 0-day vulnerabilities in the real world, like top security experts.
Unsurprisingly, as Large Language Models (LLMs) demonstrate increasing proficiency in handling complex tasks, Agent technology is emerging as a new paradigm in the field of vulnerability discovery. Since Google Project Zero released Naptime[1] last year, an increasing number of Agent-based auditing tools are appearing. By providing LLMs with the necessary toolsets and source code for testing, these tools simulate the behaviour of security researchers to perform code audits and vulnerability confirmation."><meta name=author content="DARKNAVY"><link rel=canonical href=https://www.darknavy.org/blog/argusee_a_multi_agent_collaborative_architecture_for_automated_vulnerability_discovery/><link crossorigin=anonymous href=/assets/css/stylesheet.2613b1460fae4b99a98c033e33bde5e6a3af84ddb20236b732cefe33e3c0781e.css integrity="sha256-JhOxRg+uS5mpjAM+M73l5qOvhN2yAja3Ms7+M+PAeB4=" rel="preload stylesheet" as=style><link rel=icon href=https://www.darknavy.org/images/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.darknavy.org/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.darknavy.org/favicon-32x32.png><link rel=apple-touch-icon href=https://www.darknavy.org/apple-touch-icon.png><link rel=mask-icon href=https://www.darknavy.org/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://www.darknavy.org/blog/argusee_a_multi_agent_collaborative_architecture_for_automated_vulnerability_discovery/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-LR4ZN1LSPS"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-LR4ZN1LSPS")}</script><meta property="og:url" content="https://www.darknavy.org/blog/argusee_a_multi_agent_collaborative_architecture_for_automated_vulnerability_discovery/"><meta property="og:site_name" content="DARKNAVY"><meta property="og:title" content="Argusee: A Multi-Agent Collaborative Architecture for Automated Vulnerability Discovery"><meta property="og:description" content="As we envisioned in DARKNAVY INSIGHT | The Most Imaginative New Applications of 2024:
The next generation of AI agents will have excellent reasoning and generalization abilities and be skilled at using a variety of security research tools, inheriting a wealth of human expert knowledge. They will be able to discover more 0-day vulnerabilities in the real world, like top security experts.
Unsurprisingly, as Large Language Models (LLMs) demonstrate increasing proficiency in handling complex tasks, Agent technology is emerging as a new paradigm in the field of vulnerability discovery. Since Google Project Zero released Naptime[1] last year, an increasing number of Agent-based auditing tools are appearing. By providing LLMs with the necessary toolsets and source code for testing, these tools simulate the behaviour of security researchers to perform code audits and vulnerability confirmation."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-05-23T11:09:50+08:00"><meta property="article:modified_time" content="2025-05-23T11:09:50+08:00"><meta property="og:image" content="https://www.darknavy.org/blog/argusee_a_multi_agent_collaborative_architecture_for_automated_vulnerability_discovery/attachments/cover.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.darknavy.org/blog/argusee_a_multi_agent_collaborative_architecture_for_automated_vulnerability_discovery/attachments/cover.jpg"><meta name=twitter:title content="Argusee: A Multi-Agent Collaborative Architecture for Automated Vulnerability Discovery"><meta name=twitter:description content="As we envisioned in DARKNAVY INSIGHT | The Most Imaginative New Applications of 2024:

The next generation of AI agents will have excellent reasoning and generalization abilities and be skilled at using a variety of security research tools, inheriting a wealth of human expert knowledge. They will be able to discover more 0-day vulnerabilities in the real world, like top security experts.
Unsurprisingly, as Large Language Models (LLMs) demonstrate increasing proficiency in handling complex tasks, Agent technology is emerging as a new paradigm in the field of vulnerability discovery. Since Google Project Zero released Naptime[1] last year, an increasing number of Agent-based auditing tools are appearing. By providing LLMs with the necessary toolsets and source code for testing, these tools simulate the behaviour of security researchers to perform code audits and vulnerability confirmation."><meta name=twitter:site content="@DarkNavyOrg"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://www.darknavy.org/blog/"},{"@type":"ListItem","position":2,"name":"Argusee: A Multi-Agent Collaborative Architecture for Automated Vulnerability Discovery","item":"https://www.darknavy.org/blog/argusee_a_multi_agent_collaborative_architecture_for_automated_vulnerability_discovery/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Argusee: A Multi-Agent Collaborative Architecture for Automated Vulnerability Discovery","name":"Argusee: A Multi-Agent Collaborative Architecture for Automated Vulnerability Discovery","description":"As we envisioned in DARKNAVY INSIGHT | The Most Imaginative New Applications of 2024:\nThe next generation of AI agents will have excellent reasoning and generalization abilities and be skilled at using a variety of security research tools, inheriting a wealth of human expert knowledge. They will be able to discover more 0-day vulnerabilities in the real world, like top security experts.\nUnsurprisingly, as Large Language Models (LLMs) demonstrate increasing proficiency in handling complex tasks, Agent technology is emerging as a new paradigm in the field of vulnerability discovery. Since Google Project Zero released Naptime[1] last year, an increasing number of Agent-based auditing tools are appearing. By providing LLMs with the necessary toolsets and source code for testing, these tools simulate the behaviour of security researchers to perform code audits and vulnerability confirmation.\n","keywords":[],"articleBody":"As we envisioned in DARKNAVY INSIGHT | The Most Imaginative New Applications of 2024:\nThe next generation of AI agents will have excellent reasoning and generalization abilities and be skilled at using a variety of security research tools, inheriting a wealth of human expert knowledge. They will be able to discover more 0-day vulnerabilities in the real world, like top security experts.\nUnsurprisingly, as Large Language Models (LLMs) demonstrate increasing proficiency in handling complex tasks, Agent technology is emerging as a new paradigm in the field of vulnerability discovery. Since Google Project Zero released Naptime[1] last year, an increasing number of Agent-based auditing tools are appearing. By providing LLMs with the necessary toolsets and source code for testing, these tools simulate the behaviour of security researchers to perform code audits and vulnerability confirmation.\nHowever, DARKNAVY has observed that single-agent approaches often suffer from false positives and negatives when auditing medium-to-large codebases, due to limitations in LLM reasoning (e.g., incomplete logic, hallucinations). Drawing on years of real-world vulnerability-hunting experience, DARKNAVY has proposed a multi-agent system architecture that simulates the division of labor and collaborative mechanisms within human security teams, and has implemented an automated vulnerability discovery tool called Argusee.\nIn tests on the Linux USB protocol stack, Argusee quickly discovered a high-severity vulnerability introduced since Linux version 6.5. This vulnerability has been assigned CVE-2025-37891 and has been fixed, affecting multiple mainstream distributions including Ubuntu and Arch Linux. DARKNAVY has exploited this vulnerability to reliably escalate to root privileges on Arch Linux.\nArgusee: A Multi-Agent Collaborative Architecture Argus had a hundred eyes round his head, that took their rest two at a time in succession while the others kept watch and stayed on guard.\n— Ovid: The Metamorphoses\nAlthough single-agent tools like Naptime have provided a viable paradigm for LLM-driven code auditing, they often suffer from numerous false positives and negatives when facing medium to large-scale projects. This is due to the insufficiently rigorous logic of the model reasoning and limited contextual awareness, making it difficult to flexibly adjust the audit process and meet the demands for precise localisation and in-depth verification.\nTo address this, Argusee is not intended to completely replace manual auditing or to discover vulnerabilities from scratch. Instead, it serves as a powerful assistant tool for security auditors. Given precise entry points (e.g., specific functions or modules) and relevant context from the auditor, Argusee performs in-depth analysis and identifies potential risks, thereby significantly enhancing the efficiency of professional auditors.\nUnlike existing work, Argusee’s core innovation lies in its multi-agent collaborative mechanism, which draws inspiration from the collaborative models of human security teams, decomposing complex audit tasks among agents with different roles. More importantly, compared to some early multi-agent explorations[2] where agents operated with rigid, siloed interactions, Argusee grants LLMs greater autonomy, enabling them to dynamically understand and delegate tasks, thus achieving more flexible and efficient collaborative auditing. This aligns with what Richard Sutton, the father of reinforcement learning, wrote in The Bitter Lesson: “We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.”\nAs an implementation prototype, Argusee’s architecture, shown in the figure below, primarily includes the following core agents:\nManager Agent\nThe Manager is the interaction point for the user, who provides analysis entry points (e.g., target files or functions). The Manager is responsible for understanding the task at a macro level, for example, determining the core functionality of a function, identifying potential critical code segments, and performing task decomposition and dispatch. It distributes different code snippets along with necessary contextual information to multiple Auditors.\nAuditor Agent\nAuditors focus on analysing the typically smaller code snippets assigned by the Manager. They combine contextual information to delve into code details, searching for potential vulnerabilities such as Buffer Overflows, Use After Free, etc.\nChecker Agent\nTo reduce false positives and negatives, before consolidating audit results and outputting the final conclusion, the Manager requests the Checker to review and verify the entire logical chain, identifying omissions and making corrections. Finally, the Manager integrates the information and outputs the audit report.\nDuring task execution, all Agents can call upon a predefined toolset as needed; the timing and method of tool use are autonomously decided by the Agent. On the other hand, the effective operation of the backend toolset depends on adaptation to the target project and environment. For example, the variable localisation feature of the Code Reader relies on the source code indexing capabilities established by a backend Language Server Protocol (LSP).\nTo better understand Argusee’s workflow, the figure below illustrates Argusee’s chain of thought during an actual run:\nWhen a user specifies a target file and entry function, the Manager analyzes the task and dispatches it to two Auditors. One Auditor discovers a suspected buffer overflow risk and reports it to the Manager. Subsequently, the Manager requests the Checker to review this vulnerability. The Checker ultimately confirms it as a genuine heap buffer overflow vulnerability, and the Manager produces a vulnerability audit report.\nEvaluation To validate Argusee’s effectiveness, we conducted tests and evaluations on benchmark datasets, small to medium-scale open-source projects, and very large-scale open-source projects (like the Linux Kernel).\nBenchmark Evaluation On standard single-file test cases from META CyberSecEval 2[3], Argusee demonstrated near-perfect vulnerability identification capabilities, achieving 100% accuracy on test cases for categories like Buffer Overflow.\nAuditing of Medium-Sized Open-Source Projects For medium-sized real-world open-source projects, Argusee also achieved significant results, cumulatively discovering 15 previously unknown security flaws in several well-tested projects. These projects included open-source software libraries that parse complex file formats, such as GPAC and GIFLIB.\nTaking the open-source multimedia framework GPAC[4] as an example, this project has undergone long-term Fuzz testing, and relatively few new vulnerabilities have been discovered in recent years. However, Argusee quickly identified several new vulnerabilities that are difficult to discover through traditional methods. DARKNAVY observed that Argusee performs particularly well on targets like GPAC, which have clear input formats and content parsing as their core function.\nFor instance, the code snippet below shows a memory corruption vulnerability caused by an integer overflow, discovered by Argusee. For a Fuzzer, constructing an input sample that can trigger this vulnerability (requiring zlib compression format and sufficiently large raw data to cause an overflow) is extremely difficult. Argusee, by simulating the logical reasoning process of manual auditing, successfully located this deeply buried defect.\nwhile (d_stream.total_in \u003c data_len) { err = inflate(\u0026d_stream, Z_NO_FLUSH); if (err \u003c Z_OK || err == Z_NEED_DICT) { e = GF_NON_COMPLIANT_BITSTREAM; break; } if (err==Z_STREAM_END) break; size *= 2; // u32 size, int overflow to small number *uncompressed_data = (char*)gf_realloc(*uncompressed_data, sizeof(char)*(size+1)); // realloc to small memory if (!*uncompressed_data) return GF_OUT_OF_MEM; d_stream.avail_out = (u32) (size - d_stream.total_out); // breaking the whole zlib structure d_stream.next_out = (Bytef*) ( *uncompressed_data + d_stream.total_out); } Auditing of Linux Kernel Furthermore, Argusee has also been tested on massive codebases, such as the large and complex Linux Kernel USB protocol stack. During its use, although it requires providing Agents with richer contextual information, Argusee still demonstrated strong potential in areas like assisting code comprehension and pinpointing high-risk areas, significantly accelerating audit workflows.\nThe image below shows the patch for vulnerability CVE-2025-37891[5], found by Argusee in the Linux Kernel USB protocol stack:\nThis vulnerability occurs on the host side of the Linux kernel’s USB subsystem. A malicious user can carry out an attack by inserting a simulated device that supports the USB MIDI2 protocol. For USB devices supporting MIDI2, Linux internally converts MIDI1 packets into UMP packets. Due to improper length checks, the buffer used to store the MIDI byte stream during conversion can overflow, allowing an attacker to achieve an arbitrary kernel heap overflow primitive. After being provided with the relevant functions and files for the USB MIDI2 entry point, Argusee quickly found this vulnerability and provided a clear analysis of its principle and reproduction.\nOf course, Argusee’s capabilities are not limited to this. Given that building comprehensive datasets and metrics for evaluating vulnerability discovery capabilities is a complex task in itself, more detailed evaluations and practical test results will be presented in subsequent research.\nLooking ahead, to further unleash Argusee’s potential, based on the current prototype, Argusee can be enhanced and supplemented along the following three dimensions:\nAgent System: Introduce more specialised roles, such as a Reproducer Agent responsible for constructing PoCs to verify vulnerabilities, and an Exploit Agent to assess exploitability and attempt to write exploits. Toolset: Integrate a richer set of analysis tools, such as debuggers, to help Agents understand program execution flow and vulnerability triggering processes, as well as other advanced static and dynamic analysis tools, building a powerful arsenal. Target Projects and Environments: Integrate more information sources to assist code auditing, such as using RAG technology to retrieve relevant source code knowledge and analysing compiled binary files. Epilogue Agent technology is reshaping the paradigm of vulnerability discovery, and Argusee’s success demonstrates that multi-agent collaboration can dramatically boost code-audit efficiency. By structuring LLMs with the right framework and toolsets—and combining them with human expertise—we can automate vulnerability discovery far beyond the limits of single agents. Argusee is only the beginning of this trend. At DARKNAVY, we are committed to deepening collaborative AI security research, enabling seamless teamwork between AI agents and human experts.\nOne day, analysts may be freed from tedious low-level audits to focus on strategy and risk evaluation—and in doing so, drive security research to new heights.\nReference [1] https://googleprojectzero.blogspot.com/2024/06/project-naptime.html [2] https://arxiv.org/html/2409.00899v2 [3] https://arxiv.org/abs/2404.13161 [4] https://github.com/gpac/gpac [5] https://git.kernel.org/stable/c/ce4f77bef276e7d2eb7ab03a5d08bcbaa40710ec ","wordCount":"1588","inLanguage":"en","image":"https://www.darknavy.org/blog/argusee_a_multi_agent_collaborative_architecture_for_automated_vulnerability_discovery/attachments/cover.jpg","datePublished":"2025-05-23T11:09:50+08:00","dateModified":"2025-05-23T11:09:50+08:00","author":{"@type":"Person","name":"DARKNAVY"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.darknavy.org/blog/argusee_a_multi_agent_collaborative_architecture_for_automated_vulnerability_discovery/"},"publisher":{"@type":"Organization","name":"DARKNAVY","logo":{"@type":"ImageObject","url":"https://www.darknavy.org/images/favicon.ico"}}}</script></head><body class=dark id=top><header class=header><nav class=nav><div class=logo><a href=https://www.darknavy.org/ accesskey=h title="  (Alt + H)"><img src=https://www.darknavy.org/images/darknavy_shenlan_dot.png alt aria-label=logo height=20></a><div class=logo-switches><ul class=lang-switch><li>|</li><li><a href=https://www.darknavy.org/zh/ title=Chinese aria-label=Chinese>Zh</a></li></ul></div></div><ul id=menu><li><a href=https://www.darknavy.org/ title=Home><span>Home</span></a></li><li><a href=https://www.darknavy.org/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://www.darknavy.org/darknavy_insight/ title=Insight><span>Insight</span></a></li><li><a href=https://www.darknavy.org/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://www.darknavy.org/>Home</a>&nbsp;»&nbsp;<a href=https://www.darknavy.org/blog/>Blog</a></div><h1 class="post-title entry-hint-parent">Argusee: A Multi-Agent Collaborative Architecture for Automated Vulnerability Discovery</h1><div class=post-meta><span title='2025-05-23 11:09:50 +0800 CST'>May 23, 2025</span>&nbsp;·&nbsp;1588 words&nbsp;·&nbsp;DARKNAVY</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#argusee-a-multi-agent-collaborative-architecture>Argusee: A Multi-Agent Collaborative Architecture</a></li><li><a href=#evaluation>Evaluation</a><ul><li><a href=#benchmark-evaluation>Benchmark Evaluation</a></li><li><a href=#auditing-of-medium-sized-open-source-projects>Auditing of Medium-Sized Open-Source Projects</a></li><li><a href=#auditing-of-linux-kernel>Auditing of Linux Kernel</a></li></ul></li><li><a href=#epilogue>Epilogue</a></li><li><a href=#reference>Reference</a></li></ul></nav></div></details></div><div class=post-content><p>As we envisioned in <strong><a href=https://www.darknavy.org/darknavy_insight/the_most_imaginative_new_applications_of_2024/>DARKNAVY INSIGHT | The Most Imaginative New Applications of 2024</a></strong>:</p><blockquote><p>The next generation of AI agents will have excellent reasoning and generalization abilities and be skilled at using a variety of security research tools, inheriting a wealth of human expert knowledge. They will be able to discover more 0-day vulnerabilities in the real world, like top security experts.</p></blockquote><p>Unsurprisingly, as Large Language Models (LLMs) demonstrate increasing proficiency in handling complex tasks, Agent technology is emerging as a new paradigm in the field of vulnerability discovery. Since Google Project Zero released Naptime[1] last year, an increasing number of Agent-based auditing tools are appearing. By providing LLMs with the necessary toolsets and source code for testing, these tools simulate the behaviour of security researchers to perform code audits and vulnerability confirmation.</p><p>However, DARKNAVY has observed that single-agent approaches often suffer from false positives and negatives when auditing medium-to-large codebases, due to <strong>limitations in LLM reasoning</strong> (e.g., incomplete logic, hallucinations). Drawing on years of real-world vulnerability-hunting experience, DARKNAVY has proposed a multi-agent system architecture that simulates the division of labor and collaborative mechanisms within human security teams, and has implemented <strong>an automated vulnerability discovery tool called Argusee.</strong></p><p>In tests on the Linux USB protocol stack, Argusee quickly discovered a high-severity vulnerability introduced since Linux version 6.5. This vulnerability has been assigned <strong>CVE-2025-37891</strong> and has been fixed, affecting multiple mainstream distributions including Ubuntu and Arch Linux. DARKNAVY has exploited this vulnerability to reliably escalate to root privileges on Arch Linux.</p><p><video src=attachments/exp.mp4 controls width=100% height=auto></video></p><h2 id=argusee-a-multi-agent-collaborative-architecture>Argusee: A Multi-Agent Collaborative Architecture<a hidden class=anchor aria-hidden=true href=#argusee-a-multi-agent-collaborative-architecture>#</a></h2><blockquote><p>Argus had a hundred eyes round his head, that took their rest two at a time in succession while the others kept watch and stayed on guard.</p><p><em><strong>— Ovid: The Metamorphoses</strong></em></p></blockquote><p>Although single-agent tools like Naptime have provided a viable paradigm for LLM-driven code auditing, they often suffer from numerous false positives and negatives when facing medium to large-scale projects. This is due to the insufficiently rigorous logic of the model reasoning and limited contextual awareness, making it difficult to flexibly adjust the audit process and meet the demands for precise localisation and in-depth verification.</p><p>To address this, Argusee <strong>is not intended to completely replace manual auditing or to discover vulnerabilities from scratch</strong>. Instead, it serves as a powerful assistant tool for security auditors. Given precise entry points (e.g., specific functions or modules) and relevant context from the auditor, Argusee performs in-depth analysis and identifies potential risks, thereby significantly enhancing the efficiency of professional auditors.</p><p>Unlike existing work, Argusee&rsquo;s core innovation lies in its <strong>multi-agent collaborative mechanism</strong>, which draws inspiration from the collaborative models of human security teams, decomposing complex audit tasks among agents with different roles. More importantly, compared to some early multi-agent explorations[2] where agents operated with rigid, siloed interactions, Argusee grants LLMs greater autonomy, enabling them to dynamically understand and delegate tasks, thus achieving more flexible and efficient collaborative auditing. This aligns with what Richard Sutton, the father of reinforcement learning, wrote in <strong>The Bitter Lesson</strong>: &ldquo;<strong>We want AI agents that can discover like we can</strong>, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.&rdquo;</p><p>As an implementation prototype, Argusee&rsquo;s architecture, shown in the figure below, primarily includes the following core agents:</p><img src=attachments/1e579d0f-8d65-45b4-b2e2-098931ba4c1d.png style=display:block;margin-left:auto;margin-right:auto;zoom:35%><ul><li><p><strong>Manager Agent</strong></p><p>The Manager is the interaction point for the user, who provides analysis entry points (e.g., target files or functions). The Manager is responsible for understanding the task at a macro level, for example, determining the core functionality of a function, identifying potential critical code segments, and performing task decomposition and dispatch. It distributes different code snippets along with necessary contextual information to multiple Auditors.</p></li><li><p><strong>Auditor Agent</strong></p><p>Auditors focus on analysing the typically smaller code snippets assigned by the Manager. They combine contextual information to delve into code details, searching for potential vulnerabilities such as Buffer Overflows, Use After Free, etc.</p></li><li><p><strong>Checker Agent</strong></p><p>To reduce false positives and negatives, before consolidating audit results and outputting the final conclusion, the Manager requests the Checker to review and verify the entire logical chain, identifying omissions and making corrections. Finally, the Manager integrates the information and outputs the audit report.</p></li></ul><p>During task execution, all Agents can call upon a predefined toolset as needed; the timing and method of tool use are autonomously decided by the Agent. On the other hand, the effective operation of the backend toolset depends on adaptation to the target project and environment. For example, the variable localisation feature of the Code Reader relies on the source code indexing capabilities established by a backend Language Server Protocol (LSP).</p><p>To better understand Argusee&rsquo;s workflow, the figure below illustrates Argusee&rsquo;s chain of thought during an actual run:</p><img src=attachments/628c80d1-28ad-455f-9913-ed89a6cce1ff.png style=display:block;margin-left:auto;margin-right:auto;zoom:50%><p>When a user specifies a target file and entry function, the Manager analyzes the task and dispatches it to two Auditors. One Auditor discovers a suspected buffer overflow risk and reports it to the Manager. Subsequently, the Manager requests the Checker to review this vulnerability. The Checker ultimately confirms it as a genuine heap buffer overflow vulnerability, and the Manager produces a vulnerability audit report.</p><h2 id=evaluation>Evaluation<a hidden class=anchor aria-hidden=true href=#evaluation>#</a></h2><p>To validate Argusee&rsquo;s effectiveness, we conducted tests and evaluations on benchmark datasets, small to medium-scale open-source projects, and very large-scale open-source projects (like the Linux Kernel).</p><h3 id=benchmark-evaluation>Benchmark Evaluation<a hidden class=anchor aria-hidden=true href=#benchmark-evaluation>#</a></h3><p>On standard single-file test cases from META CyberSecEval 2[3], Argusee demonstrated near-perfect vulnerability identification capabilities, achieving <strong>100% accuracy</strong> on test cases for categories like Buffer Overflow.</p><h3 id=auditing-of-medium-sized-open-source-projects>Auditing of Medium-Sized Open-Source Projects<a hidden class=anchor aria-hidden=true href=#auditing-of-medium-sized-open-source-projects>#</a></h3><p>For medium-sized real-world open-source projects, Argusee also achieved significant results, cumulatively discovering <strong>15 previously unknown security flaws</strong> in several well-tested projects. These projects included open-source software libraries that parse complex file formats, such as GPAC and GIFLIB.</p><p>Taking the open-source multimedia framework GPAC[4] as an example, this project has undergone long-term Fuzz testing, and relatively few new vulnerabilities have been discovered in recent years. However, <strong>Argusee quickly identified several new vulnerabilities that are difficult to discover through traditional methods</strong>. DARKNAVY observed that Argusee performs particularly well on targets like GPAC, which have clear input formats and content parsing as their core function.</p><p>For instance, the code snippet below shows a <strong>memory corruption vulnerability</strong> caused by an <strong>integer overflow</strong>, discovered by Argusee. For a Fuzzer, constructing an input sample that can trigger this vulnerability (requiring zlib compression format and sufficiently large raw data to cause an overflow) is extremely difficult. Argusee, by simulating the logical reasoning process of manual auditing, successfully located this deeply buried defect.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>while</span> <span class=p>(</span><span class=n>d_stream</span><span class=p>.</span><span class=n>total_in</span> <span class=o>&lt;</span> <span class=n>data_len</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>err</span> <span class=o>=</span> <span class=nf>inflate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>d_stream</span><span class=p>,</span> <span class=n>Z_NO_FLUSH</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=p>(</span><span class=n>err</span> <span class=o>&lt;</span> <span class=n>Z_OK</span> <span class=o>||</span> <span class=n>err</span> <span class=o>==</span> <span class=n>Z_NEED_DICT</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>e</span> <span class=o>=</span> <span class=n>GF_NON_COMPLIANT_BITSTREAM</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		<span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=p>(</span><span class=n>err</span><span class=o>==</span><span class=n>Z_STREAM_END</span><span class=p>)</span> <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>size</span> <span class=o>*=</span> <span class=mi>2</span><span class=p>;</span>  <span class=c1>// u32 size, int overflow to small number
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=o>*</span><span class=n>uncompressed_data</span> <span class=o>=</span> <span class=p>(</span><span class=kt>char</span><span class=o>*</span><span class=p>)</span><span class=nf>gf_realloc</span><span class=p>(</span><span class=o>*</span><span class=n>uncompressed_data</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>char</span><span class=p>)</span><span class=o>*</span><span class=p>(</span><span class=n>size</span><span class=o>+</span><span class=mi>1</span><span class=p>));</span>  <span class=c1>// realloc to small memory
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=k>if</span> <span class=p>(</span><span class=o>!*</span><span class=n>uncompressed_data</span><span class=p>)</span> <span class=k>return</span> <span class=n>GF_OUT_OF_MEM</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=n>d_stream</span><span class=p>.</span><span class=n>avail_out</span> <span class=o>=</span> <span class=p>(</span><span class=n>u32</span><span class=p>)</span> <span class=p>(</span><span class=n>size</span> <span class=o>-</span> <span class=n>d_stream</span><span class=p>.</span><span class=n>total_out</span><span class=p>);</span>  <span class=c1>// breaking the whole zlib structure
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=n>d_stream</span><span class=p>.</span><span class=n>next_out</span> <span class=o>=</span> <span class=p>(</span><span class=n>Bytef</span><span class=o>*</span><span class=p>)</span> <span class=p>(</span> <span class=o>*</span><span class=n>uncompressed_data</span> <span class=o>+</span> <span class=n>d_stream</span><span class=p>.</span><span class=n>total_out</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=auditing-of-linux-kernel>Auditing of Linux Kernel<a hidden class=anchor aria-hidden=true href=#auditing-of-linux-kernel>#</a></h3><p>Furthermore, Argusee has also been tested on massive codebases, such as the large and complex <strong>Linux Kernel USB protocol stack</strong>. During its use, although it requires providing Agents with richer contextual information, Argusee still demonstrated strong potential in areas like assisting code comprehension and pinpointing high-risk areas, significantly accelerating audit workflows.</p><p>The image below shows the patch for vulnerability CVE-2025-37891[5], found by Argusee in the Linux Kernel USB protocol stack:</p><img src=attachments/f1c77aba-d5fb-408b-8095-fe2ee50097f3.png style=display:block;margin-left:auto;margin-right:auto;zoom:40%><p>This vulnerability occurs on the host side of the Linux kernel&rsquo;s USB subsystem. A malicious user can carry out an attack by inserting a simulated device that supports the USB MIDI2 protocol. For USB devices supporting MIDI2, Linux internally converts MIDI1 packets into UMP packets. <strong>Due to improper length checks, the buffer used to store the MIDI byte stream during conversion can overflow</strong>, allowing an attacker to achieve an arbitrary kernel heap overflow primitive. After being provided with the relevant functions and files for the USB MIDI2 entry point, Argusee quickly found this vulnerability and provided a clear analysis of its principle and reproduction.</p><p>Of course, Argusee&rsquo;s capabilities are not limited to this. Given that building comprehensive datasets and metrics for evaluating vulnerability discovery capabilities is a complex task in itself, more detailed evaluations and practical test results will be presented in subsequent research.</p><p>Looking ahead, to further unleash Argusee&rsquo;s potential, based on the current prototype, Argusee can be enhanced and supplemented along the following three dimensions:</p><ul><li><strong>Agent System:</strong> Introduce more specialised roles, such as a Reproducer Agent responsible for constructing PoCs to verify vulnerabilities, and an Exploit Agent to assess exploitability and attempt to write exploits.</li><li><strong>Toolset:</strong> Integrate a richer set of analysis tools, such as debuggers, to help Agents understand program execution flow and vulnerability triggering processes, as well as other advanced static and dynamic analysis tools, building a powerful arsenal.</li><li><strong>Target Projects and Environments:</strong> Integrate more information sources to assist code auditing, such as using RAG technology to retrieve relevant source code knowledge and analysing compiled binary files.</li></ul><h2 id=epilogue>Epilogue<a hidden class=anchor aria-hidden=true href=#epilogue>#</a></h2><p>Agent technology is reshaping the paradigm of vulnerability discovery, and Argusee&rsquo;s success demonstrates that multi-agent collaboration can dramatically boost code-audit efficiency. By structuring LLMs with the right framework and toolsets—and combining them with human expertise—we can automate vulnerability discovery far beyond the limits of single agents. Argusee is only the beginning of this trend. At DARKNAVY, we are committed to deepening collaborative AI security research, enabling seamless teamwork between AI agents and human experts.</p><p>One day, analysts may be freed from tedious low-level audits to focus on strategy and risk evaluation—and in doing so, drive security research to new heights.</p><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><ul><li>[1] <a href=https://googleprojectzero.blogspot.com/2024/06/project-naptime.html>https://googleprojectzero.blogspot.com/2024/06/project-naptime.html</a></li><li>[2] <a href=https://arxiv.org/html/2409.00899v2>https://arxiv.org/html/2409.00899v2</a></li><li>[3] <a href=https://arxiv.org/abs/2404.13161>https://arxiv.org/abs/2404.13161</a></li><li>[4] <a href=https://github.com/gpac/gpac>https://github.com/gpac/gpac</a></li><li>[5] <a href=https://git.kernel.org/stable/c/ce4f77bef276e7d2eb7ab03a5d08bcbaa40710ec>https://git.kernel.org/stable/c/ce4f77bef276e7d2eb7ab03a5d08bcbaa40710ec</a></li></ul></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://www.darknavy.org/blog/if_the_person_who_finds_a_web3_hardware_wallet_is_a_hacker/><span class=title>Next »</span><br><span>If the Person Who Finds a Web3 Hardware Wallet is a Hacker</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://www.darknavy.org/>DARKNAVY</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script></body></html>